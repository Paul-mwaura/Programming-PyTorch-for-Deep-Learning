{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNWkXIiMginL+0/EKA09mHP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paul-mwaura/Programming-PyTorch-for-Deep-Learning/blob/main/Introduction_to_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfmSKiMFP3L2"
      },
      "source": [
        "## Introduction to Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jS_UVobP6_p"
      },
      "source": [
        "### Importing the Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT7d2W4fMToY"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIOIFuEzP-3b",
        "outputId": "1a97ec9a-f380-46c6-8298-5e9de7cb1bfc"
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfGKsbH7Qfn2"
      },
      "source": [
        "> `torch.cuda.is_available()` should return \"True\"\n",
        "\n",
        "> If it evaluates to \"False\", change your colab runtime to GPU, then run the code from top."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fipkbw9QQGPc",
        "outputId": "787d1d53-d3e8-4326-c980-2a32c5c67f5a"
      },
      "source": [
        "print(torch.rand(2,2)) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2249, 0.3785],\n",
            "        [0.6265, 0.4632]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmk_nsAHRnmW"
      },
      "source": [
        "### Tensors \n",
        "A tensor is both a container for numbers as well as a set of rules that define transformations between tensors that produce new tensors.\n",
        "\n",
        "Think about tensors as multidimensional arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeLuLs2OQXxZ",
        "outputId": "d578141a-3871-4daa-88f0-a5bac30c2c30"
      },
      "source": [
        "x = torch.tensor([[0,0,1],[1,1,1],[0,0,0]]) \n",
        "x"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 1],\n",
              "        [1, 1, 1],\n",
              "        [0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tUZWiceSTBS"
      },
      "source": [
        "Change an element in a tensor by using standard Python indexing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr4pGLAnSNWm",
        "outputId": "92b15576-115a-4898-86eb-573c1e840237"
      },
      "source": [
        "x[0][0] = 7\n",
        "x[1][1] = 7\n",
        "x[2][2] = 7\n",
        "\n",
        "x"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7, 0, 1],\n",
              "        [1, 7, 1],\n",
              "        [0, 0, 7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH1A2O6mSskh"
      },
      "source": [
        "You can use special creation functions to generate particular types of tensors. In particular, ones() and zeroes() will generate tensors filled with 1s and 0s, respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww20-11wSZhm",
        "outputId": "d50f579e-b6ae-4fba-ad62-9a4018bb9e28"
      },
      "source": [
        "torch.zeros(2,2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epMxUh6ASwDM",
        "outputId": "bf731e6b-0630-4776-f982-0b8e8a747154"
      },
      "source": [
        "torch.ones(4,4)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gARqjaj_S7ti"
      },
      "source": [
        "Standard mathematical operations with tensors (e.g., adding two tensors together)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSG9KQ9mSzHZ",
        "outputId": "8b633e6d-ae3e-4900-8950-0eb43f56017d"
      },
      "source": [
        "torch.ones(1,2) + torch.ones(1,2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIaSqh1DTcaw"
      },
      "source": [
        "If you have a tensor of rank 0, you can pull out the value with item()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb17DO8MTGgW",
        "outputId": "7de167cb-6e77-4807-d52e-a8d6af048a02"
      },
      "source": [
        "torch.rand(1).item()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5123191475868225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG7Pil45Tjxv"
      },
      "source": [
        "Tensors can live in the CPU or on the GPU and can be copied between devices by using the to() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzg2f5uaTQJ8",
        "outputId": "d89494a9-6f65-44f2-e83b-cded2920d6a1"
      },
      "source": [
        "cpu_tensor = torch.rand(2,2) \n",
        "print(cpu_tensor.device)\n",
        "print(cpu_tensor)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "tensor([[0.0041, 0.3583],\n",
            "        [0.2925, 0.6987]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-bO6GzfTpR-",
        "outputId": "e1f836fe-5140-44ce-9f70-8cbfaf39a7bc"
      },
      "source": [
        "gpu_tensor = cpu_tensor.to(\"cuda\") \n",
        "print(gpu_tensor.device)\n",
        "print(gpu_tensor) "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "tensor([[0.0041, 0.3583],\n",
            "        [0.2925, 0.6987]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPjH0hn2UNql"
      },
      "source": [
        "### Tensor Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hTrv6_2VLkV"
      },
      "source": [
        "We often need to find the maximum item in a tensor as well as the index that contains the maximum value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwNUyU9WT3MD",
        "outputId": "68fae716-9ad6-4663-eae2-e95cae3e56b4"
      },
      "source": [
        "torch.rand(2,2).max()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5002)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brRVt6ENVXYZ",
        "outputId": "76868237-77d5-4510-b6f1-32aee57a8fd9"
      },
      "source": [
        "torch.rand(2,2).max().item()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9984431266784668"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYP0d61pVk-h"
      },
      "source": [
        "Sometimes, we’d like to change the type of a tensor; for example, from a LongTensor to a FloatTensor. We can do this with to():\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vpUrqyzVVd3j",
        "outputId": "bdcd2817-8c5d-45d8-b466-b78dc7d698ec"
      },
      "source": [
        "long_tensor = torch.tensor([[0,0,1],[1,1,1],[0,0,0]])\n",
        "long_tensor.type()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.LongTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "umRQb69GVvwp",
        "outputId": "636b8d16-fa71-4824-ac65-e0f4200d43d3"
      },
      "source": [
        "float_tensor = torch.tensor([[0,0,1],[1,1,1],[0,0,0]]).to(dtype=torch.float32) \n",
        "float_tensor.type() "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "tjL7TUqRV2zk",
        "outputId": "3eaa1121-aef4-46fb-beb7-52ea00dccfd8"
      },
      "source": [
        "float_tensor = torch.tensor(long_tensor).to(dtype=torch.float32)\n",
        "float_tensor.type()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ethcbd7zWRAR"
      },
      "source": [
        "If you want to save memory, look to see if an in-place function is defined, which should be the same name as the original function but with an appended underscore (_).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7HjYPXzWFEu",
        "outputId": "d5c5cd34-1337-46e4-ce84-3abca7ee946a"
      },
      "source": [
        "random_tensor = torch.rand(2,2) \n",
        "random_tensor.log2()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.1251, -0.4932],\n",
              "        [-0.1851, -2.7723]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQf-INqkWYAC",
        "outputId": "f25791f9-a971-4536-f55b-8afd744bfd07"
      },
      "source": [
        "random_tensor.log2_()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.1251, -0.4932],\n",
              "        [-0.1851, -2.7723]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gpt80Y_EW19e"
      },
      "source": [
        "Another common operation is reshaping a tensor. This can often occur because your neural network layer may require a slightly different input shape than what you currently have to feed into it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umhZcpDzWakn",
        "outputId": "04ae449b-cc52-4554-ec8d-ccd7de7dce44"
      },
      "source": [
        "flat_tensor = torch.rand(784) \n",
        "viewed_tensor = flat_tensor.view(1,28,28) \n",
        "print(f\"Flat tensor: {flat_tensor[:15,]}\") # let's print the first 15 values.\n",
        "print(f\"Viewed tensor :{viewed_tensor.shape}\") "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Flat tensor: tensor([0.9707, 0.4345, 0.2709, 0.8198, 0.2541, 0.7674, 0.9412, 0.4782, 0.3368,\n",
            "        0.1648, 0.9091, 0.5670, 0.8138, 0.4993, 0.8596])\n",
            "Viewed tensor :torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eerZnz8OXL3D",
        "outputId": "f6e5b10b-99d2-48a5-be9f-a13e30c1d0bb"
      },
      "source": [
        "reshaped_tensor = flat_tensor.reshape(1,28,28) \n",
        "reshaped_tensor.shape "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yMYTzkTX1cy"
      },
      "source": [
        "> Note that the reshaped tensor’s shape has to have the same number of total elements as the original. If you try flat_tensor.reshape(3,28,28), you’ll see an error like this:\n",
        "```\n",
        "RuntimeError Traceback (most recent call last) <ipython-input-26-774c70ba5c08> in <module>() \n",
        "----> 1 flat_tensor.reshape(3,28,28)\n",
        "RuntimeError: shape '[3, 28, 28]' is invalid for input of size 784\n",
        "```\n",
        "The answer is that view() operates as a view on the original tensor, so if the underlying data is changed, the view will change too (and vice versa). However, view() can throw errors if the required view is not contiguous; that is, it doesn’t share the same block of memory it would occupy if a new tensor of the required shape was created from scratch. If this happens, you have to call tensor.contiguous() before you can use view(). However, reshape() does all that behind the scenes, so in general, I recommend using reshape() rather than view().\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbajdh0FY0ll"
      },
      "source": [
        "> Finally, you might need to rearrange the dimensions of a tensor. You will likely come across this with images, which often are stored as [height, width, channel] tensors, but PyTorch prefers to deal with these in a [channel, height, width]. You can user permute() to deal with these in a fairly straightforward manner:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9Jh4kzWXt48",
        "outputId": "eaf34b8e-851a-46cf-99e0-b393dd67dbb9"
      },
      "source": [
        "hwc_tensor = torch.rand(640, 480, 3) \n",
        "chw_tensor = hwc_tensor.permute(2,0,1) \n",
        "chw_tensor.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 640, 480])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5317ZD7raHnv"
      },
      "source": [
        "Here, we’ve just applied permute to a [640,480,3] tensor, with the arguments being the indexes of the tensor’s dimensions, so we want the final dimension (2, due to zero indexing) to be at the front of our tensor, followed by the remaining two dimensions in their original order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwlL45Y6eSLU"
      },
      "source": [
        "### Tensor Broadcasting \n",
        "\n",
        "Borrowed from NumPy, broadcasting allows you to perform operations between a tensor and a smaller tensor. You can broadcast across two tensors if, starting backward from their trailing dimensions: • The two dimensions are equal. • One of the dimensions is 1. In our use of broadcasting, it works because 1 has a dimension of 1, and as there are no other dimensions, the 1 can be expanded to cover the other tensor. If we tried to add a [2,2] tensor to a [3,3] tensor, we’d get this error message:\n",
        "\n",
        "`The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1 `\n",
        "\n",
        "But we could add a [1,3] tensor to the [3,3] tensor without any trouble. Broadcasting is a handy little feature that increases brevity of code, and is often faster than manually expanding the tensor yourself."
      ]
    }
  ]
}